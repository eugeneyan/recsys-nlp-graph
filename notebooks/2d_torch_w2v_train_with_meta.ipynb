{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.ml.data_loader_with_meta import Sequences, SequencesDataset\n",
    "from src.ml.skipgram import SkipGram as SkipGramBase\n",
    "from src.ml.skipgram_with_meta import SkipGram\n",
    "from src.utils.logger import logger\n",
    "from src.utils.io_utils import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 1\n",
    "shuffle = False\n",
    "num_workers = 4\n",
    "emb_dim = 8\n",
    "epochs = 1\n",
    "initial_lr=0.025\n",
    "MODEL_PATH = '../model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'electronics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0b6cb2ee9d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sequences = Sequences('../data/{}_sequences_samp.npy'.format(dataset), \n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0;34m'../data/{}_edges_val_samp.csv'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       '../data/{}_meta.csv'.format(dataset))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequences' is not defined"
     ]
    }
   ],
   "source": [
    "sequences = Sequences('../data/{}_sequences_samp.npy'.format(dataset), \n",
    "                      '../data/{}_edges_val_samp.csv'.format(dataset),\n",
    "                      '../data/{}_meta.csv'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_dset = SequencesDataset(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_dload = DataLoader(sequences_dset, batch_size=batchsize, shuffle=shuffle, num_workers=num_workers, collate_fn=sequences_dset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram = SkipGram(sequences.emb_sizes, emb_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('../data/{}_meta.csv'.format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>description</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>related</th>\n",
       "      <th>brand</th>\n",
       "      <th>category_lvl_1</th>\n",
       "      <th>category_lvl_2</th>\n",
       "      <th>category_lvl_3</th>\n",
       "      <th>category_lvl_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0132793040</td>\n",
       "      <td>the kelby training dvd mastering blend modes i...</td>\n",
       "      <td>['electronics', 'computers &amp; accessories', 'ca...</td>\n",
       "      <td>kelby training dvd: mastering blend modes in a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; accessories</td>\n",
       "      <td>cables &amp; accessories</td>\n",
       "      <td>monitor accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0321732944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['electronics', 'computers &amp; accessories', 'ca...</td>\n",
       "      <td>kelby training dvd: adobe photoshop cs5 crash ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; accessories</td>\n",
       "      <td>cables &amp; accessories</td>\n",
       "      <td>monitor accessories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0439886341</td>\n",
       "      <td>digital organizer and messenger</td>\n",
       "      <td>['electronics', 'computers &amp; accessories', 'pd...</td>\n",
       "      <td>digital organizer and messenger</td>\n",
       "      <td>8.15</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; accessories</td>\n",
       "      <td>pdas, handhelds &amp; accessories</td>\n",
       "      <td>pdas &amp; handhelds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0511189877</td>\n",
       "      <td>the clikr-5 ur5u-8780l remote control is desig...</td>\n",
       "      <td>['electronics', 'accessories &amp; supplies', 'aud...</td>\n",
       "      <td>clikr-5 time warner cable remote control ur5u-...</td>\n",
       "      <td>23.36</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>electronics</td>\n",
       "      <td>accessories &amp; supplies</td>\n",
       "      <td>audio &amp; video accessories</td>\n",
       "      <td>remote controls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0528881469</td>\n",
       "      <td>like its award-winning predecessor, the intell...</td>\n",
       "      <td>['electronics', 'gps &amp; navigation', 'vehicle g...</td>\n",
       "      <td>rand mcnally 528881469 7-inch intelliroute tnd...</td>\n",
       "      <td>299.99</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>electronics</td>\n",
       "      <td>gps &amp; navigation</td>\n",
       "      <td>vehicle gps</td>\n",
       "      <td>trucking gps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498191</th>\n",
       "      <td>bt008v9j9u</td>\n",
       "      <td>vehicle suction cup mount (replacement) notice...</td>\n",
       "      <td>['electronics', 'gps &amp; navigation', 'gps syste...</td>\n",
       "      <td>suction cup mount</td>\n",
       "      <td>21.99</td>\n",
       "      <td>1</td>\n",
       "      <td>garmin</td>\n",
       "      <td>electronics</td>\n",
       "      <td>gps &amp; navigation</td>\n",
       "      <td>gps system accessories</td>\n",
       "      <td>vehicle mounts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498192</th>\n",
       "      <td>bt008sxq4c</td>\n",
       "      <td>quatech - 1 port pcmcia to db-25 parallel adap...</td>\n",
       "      <td>['electronics', 'computers &amp; accessories', 'ca...</td>\n",
       "      <td>parallel pcmcia card 1port epp</td>\n",
       "      <td>23.99</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; accessories</td>\n",
       "      <td>cables &amp; accessories</td>\n",
       "      <td>cables &amp; interconnects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498193</th>\n",
       "      <td>bt008g3w52</td>\n",
       "      <td>c2g - 5m ultma usb 2.0 a mini b cble</td>\n",
       "      <td>['electronics', 'computers &amp; accessories', 'ca...</td>\n",
       "      <td>c2g / cables to go 5m ultima usb 2.0 cable</td>\n",
       "      <td>18.91</td>\n",
       "      <td>1</td>\n",
       "      <td>c2g</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; accessories</td>\n",
       "      <td>cables &amp; accessories</td>\n",
       "      <td>cables &amp; interconnects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498194</th>\n",
       "      <td>bt008uktmw</td>\n",
       "      <td>keyboard drawer.</td>\n",
       "      <td>['electronics', 'computers &amp; accessories', 'ca...</td>\n",
       "      <td>underdesk keyboard drawer</td>\n",
       "      <td>25.54</td>\n",
       "      <td>1</td>\n",
       "      <td>fellowes</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; accessories</td>\n",
       "      <td>cables &amp; accessories</td>\n",
       "      <td>keyboards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498195</th>\n",
       "      <td>bt008t2bgk</td>\n",
       "      <td>garmin usb to r232 converter cableusb to rs232...</td>\n",
       "      <td>['electronics', 'computers &amp; accessories', 'ca...</td>\n",
       "      <td>usb to r232 converter cable</td>\n",
       "      <td>62.31</td>\n",
       "      <td>1</td>\n",
       "      <td>garmin</td>\n",
       "      <td>electronics</td>\n",
       "      <td>computers &amp; accessories</td>\n",
       "      <td>cables &amp; accessories</td>\n",
       "      <td>computer cable adapters</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498196 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              asin                                        description  \\\n",
       "0       0132793040  the kelby training dvd mastering blend modes i...   \n",
       "1       0321732944                                                NaN   \n",
       "2       0439886341                    digital organizer and messenger   \n",
       "3       0511189877  the clikr-5 ur5u-8780l remote control is desig...   \n",
       "4       0528881469  like its award-winning predecessor, the intell...   \n",
       "...            ...                                                ...   \n",
       "498191  bt008v9j9u  vehicle suction cup mount (replacement) notice...   \n",
       "498192  bt008sxq4c  quatech - 1 port pcmcia to db-25 parallel adap...   \n",
       "498193  bt008g3w52               c2g - 5m ultma usb 2.0 a mini b cble   \n",
       "498194  bt008uktmw                                   keyboard drawer.   \n",
       "498195  bt008t2bgk  garmin usb to r232 converter cableusb to rs232...   \n",
       "\n",
       "                                               categories  \\\n",
       "0       ['electronics', 'computers & accessories', 'ca...   \n",
       "1       ['electronics', 'computers & accessories', 'ca...   \n",
       "2       ['electronics', 'computers & accessories', 'pd...   \n",
       "3       ['electronics', 'accessories & supplies', 'aud...   \n",
       "4       ['electronics', 'gps & navigation', 'vehicle g...   \n",
       "...                                                   ...   \n",
       "498191  ['electronics', 'gps & navigation', 'gps syste...   \n",
       "498192  ['electronics', 'computers & accessories', 'ca...   \n",
       "498193  ['electronics', 'computers & accessories', 'ca...   \n",
       "498194  ['electronics', 'computers & accessories', 'ca...   \n",
       "498195  ['electronics', 'computers & accessories', 'ca...   \n",
       "\n",
       "                                                    title   price  related  \\\n",
       "0       kelby training dvd: mastering blend modes in a...     NaN        0   \n",
       "1       kelby training dvd: adobe photoshop cs5 crash ...     NaN        0   \n",
       "2                         digital organizer and messenger    8.15        1   \n",
       "3       clikr-5 time warner cable remote control ur5u-...   23.36        1   \n",
       "4       rand mcnally 528881469 7-inch intelliroute tnd...  299.99        1   \n",
       "...                                                   ...     ...      ...   \n",
       "498191                                  suction cup mount   21.99        1   \n",
       "498192                     parallel pcmcia card 1port epp   23.99        1   \n",
       "498193         c2g / cables to go 5m ultima usb 2.0 cable   18.91        1   \n",
       "498194                          underdesk keyboard drawer   25.54        1   \n",
       "498195                        usb to r232 converter cable   62.31        1   \n",
       "\n",
       "           brand category_lvl_1           category_lvl_2  \\\n",
       "0            NaN    electronics  computers & accessories   \n",
       "1            NaN    electronics  computers & accessories   \n",
       "2            NaN    electronics  computers & accessories   \n",
       "3            NaN    electronics   accessories & supplies   \n",
       "4            NaN    electronics         gps & navigation   \n",
       "...          ...            ...                      ...   \n",
       "498191    garmin    electronics         gps & navigation   \n",
       "498192       NaN    electronics  computers & accessories   \n",
       "498193       c2g    electronics  computers & accessories   \n",
       "498194  fellowes    electronics  computers & accessories   \n",
       "498195    garmin    electronics  computers & accessories   \n",
       "\n",
       "                       category_lvl_3           category_lvl_4  \n",
       "0                cables & accessories      monitor accessories  \n",
       "1                cables & accessories      monitor accessories  \n",
       "2       pdas, handhelds & accessories         pdas & handhelds  \n",
       "3           audio & video accessories          remote controls  \n",
       "4                         vehicle gps             trucking gps  \n",
       "...                               ...                      ...  \n",
       "498191         gps system accessories           vehicle mounts  \n",
       "498192           cables & accessories   cables & interconnects  \n",
       "498193           cables & accessories   cables & interconnects  \n",
       "498194           cables & accessories                keyboards  \n",
       "498195           cables & accessories  computer cable adapters  \n",
       "\n",
       "[498196 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 15:14:21,207 - Epoch: 0, Seq Count: 0/5000, Loss: 0.0404, Lr: 0.025000\n",
      "2019-12-09 15:14:22,184 - Epoch: 0, Seq Count: 100/5000, Loss: 0.9065, Lr: 0.024975\n",
      "2019-12-09 15:14:23,144 - Epoch: 0, Seq Count: 200/5000, Loss: 0.8626, Lr: 0.024900\n",
      "2019-12-09 15:14:24,094 - Epoch: 0, Seq Count: 300/5000, Loss: 0.5013, Lr: 0.024777\n",
      "2019-12-09 15:14:25,045 - Epoch: 0, Seq Count: 400/5000, Loss: 0.7018, Lr: 0.024605\n",
      "2019-12-09 15:14:25,986 - Epoch: 0, Seq Count: 500/5000, Loss: 0.8305, Lr: 0.024386\n",
      "2019-12-09 15:14:26,932 - Epoch: 0, Seq Count: 600/5000, Loss: 0.8488, Lr: 0.024119\n",
      "2019-12-09 15:14:27,907 - Epoch: 0, Seq Count: 700/5000, Loss: 0.8957, Lr: 0.023807\n",
      "2019-12-09 15:14:28,862 - Epoch: 0, Seq Count: 800/5000, Loss: 0.9884, Lr: 0.023450\n",
      "2019-12-09 15:14:29,851 - Epoch: 0, Seq Count: 900/5000, Loss: 1.0634, Lr: 0.023050\n",
      "2019-12-09 15:14:30,839 - Epoch: 0, Seq Count: 1,000/5000, Loss: 0.6308, Lr: 0.022608\n",
      "2019-12-09 15:14:31,755 - Epoch: 0, Seq Count: 1,100/5000, Loss: 0.9069, Lr: 0.022126\n",
      "2019-12-09 15:14:32,697 - Epoch: 0, Seq Count: 1,200/5000, Loss: 1.0245, Lr: 0.021607\n",
      "2019-12-09 15:14:33,640 - Epoch: 0, Seq Count: 1,300/5000, Loss: 1.2410, Lr: 0.021051\n",
      "2019-12-09 15:14:34,596 - Epoch: 0, Seq Count: 1,400/5000, Loss: 0.9946, Lr: 0.020462\n",
      "2019-12-09 15:14:35,573 - Epoch: 0, Seq Count: 1,500/5000, Loss: 1.3075, Lr: 0.019841\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-32fbbc98bf93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_contexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recsys/venv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recsys/venv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.SparseAdam(skipgram.parameters(), lr=initial_lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(sequences_dload))\n",
    "    \n",
    "    running_loss = 0\n",
    "    for i, batches in enumerate(sequences_dload):\n",
    "\n",
    "        # logger.info('Batch shape: {}, {}, {}'.format(batches[0].shape, batches[1].shape, batches[2].shape))\n",
    "        centers = batches[0].to(device)\n",
    "        contexts = batches[1].to(device)\n",
    "        neg_contexts = batches[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = skipgram.forward(centers, contexts, neg_contexts)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        running_loss = running_loss * 0.9 + loss.item() * 0.1\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            logger.info('Epoch: {:,}, Seq Count: {:,}/{}, Loss: {:.4f}, Lr: {:.6f}'.format(epoch, i, len(sequences_dload), running_loss,\n",
    "                                                                                        optimizer.param_groups[0][\n",
    "                                                                                            'lr']))\n",
    "            running_loss = 0\n",
    "\n",
    "    # skipgram.save_embeddings(file_name='{}/skipgram_epoch_{}.npy'.format(MODEL_PATH, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([65, 2])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10662,     4],\n",
       "        [10662,     4],\n",
       "        [10662,     4],\n",
       "        [10662,     4],\n",
       "        [10662,     4],\n",
       "        [10671,     0],\n",
       "        [10671,     0],\n",
       "        [10671,     0],\n",
       "        [10671,     0],\n",
       "        [10671,     0],\n",
       "        [10679,     3],\n",
       "        [10679,     3],\n",
       "        [10679,     3],\n",
       "        [10679,     3],\n",
       "        [10679,     3],\n",
       "        [10679,     3],\n",
       "        [10699,     0],\n",
       "        [10699,     0],\n",
       "        [10699,     0],\n",
       "        [10699,     0],\n",
       "        [10699,     0],\n",
       "        [10699,     0],\n",
       "        [10699,     0],\n",
       "        [10700,     3],\n",
       "        [10700,     3],\n",
       "        [10700,     3],\n",
       "        [10700,     3],\n",
       "        [10700,     3],\n",
       "        [10700,     3],\n",
       "        [10700,     3],\n",
       "        [10700,     3],\n",
       "        [ 5923,     3],\n",
       "        [ 5923,     3],\n",
       "        [ 5923,     3],\n",
       "        [ 5923,     3],\n",
       "        [ 5923,     3],\n",
       "        [ 5923,     3],\n",
       "        [ 5923,     3],\n",
       "        [ 5923,     3],\n",
       "        [10701,     0],\n",
       "        [10701,     0],\n",
       "        [10701,     0],\n",
       "        [10701,     0],\n",
       "        [10701,     0],\n",
       "        [10701,     0],\n",
       "        [10701,     0],\n",
       "        [10701,     0],\n",
       "        [10702,     3],\n",
       "        [10702,     3],\n",
       "        [10702,     3],\n",
       "        [10702,     3],\n",
       "        [10702,     3],\n",
       "        [10702,     3],\n",
       "        [10702,     3],\n",
       "        [10703,     3],\n",
       "        [10703,     3],\n",
       "        [10703,     3],\n",
       "        [10703,     3],\n",
       "        [10703,     3],\n",
       "        [10703,     3],\n",
       "        [ 2287,     3],\n",
       "        [ 2287,     3],\n",
       "        [ 2287,     3],\n",
       "        [ 2287,     3],\n",
       "        [ 2287,     3]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 15:14:54,195 - center i: 0, center: tensor([10662, 10662, 10662, 10662, 10662, 10671, 10671, 10671, 10671, 10671,\n",
      "        10679, 10679, 10679, 10679, 10679, 10679, 10699, 10699, 10699, 10699,\n",
      "        10699, 10699, 10699, 10700, 10700, 10700, 10700, 10700, 10700, 10700,\n",
      "        10700,  5923,  5923,  5923,  5923,  5923,  5923,  5923,  5923, 10701,\n",
      "        10701, 10701, 10701, 10701, 10701, 10701, 10701, 10702, 10702, 10702,\n",
      "        10702, 10702, 10702, 10702, 10703, 10703, 10703, 10703, 10703, 10703,\n",
      "         2287,  2287,  2287,  2287,  2287])\n",
      "2019-12-09 15:14:54,197 - center i: 1, center: tensor([4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "emb_centers = []\n",
    "for i in range(centers.shape[1]):\n",
    "    logger.info('center i: {}, center: {}'.format(i, centers[:, i]))\n",
    "    emb_centers.append(skipgram.center_embeddings[i](centers[:, i]))\n",
    "emb_center = torch.mean(torch.stack(emb_centers), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weights = nn.Embedding(133050, len(sequences.meta_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "embs = torch.stack(emb_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0918,  0.1411,  0.2642,  ...,  0.0383,  0.1361, -0.0501],\n",
       "         [ 0.0918,  0.1411,  0.2642,  ...,  0.0383,  0.1361, -0.0501],\n",
       "         [ 0.0918,  0.1411,  0.2642,  ...,  0.0383,  0.1361, -0.0501],\n",
       "         ...,\n",
       "         [ 0.0904,  0.1429, -0.1467,  ...,  0.0428, -0.1430, -0.0881],\n",
       "         [ 0.0904,  0.1429, -0.1467,  ...,  0.0428, -0.1430, -0.0881],\n",
       "         [ 0.0904,  0.1429, -0.1467,  ...,  0.0428, -0.1430, -0.0881]],\n",
       "\n",
       "        [[ 1.4873,  0.1554,  1.6058,  ...,  0.1069,  2.0883, -0.1213],\n",
       "         [ 1.4873,  0.1554,  1.6058,  ...,  0.1069,  2.0883, -0.1213],\n",
       "         [ 1.4873,  0.1554,  1.6058,  ...,  0.1069,  2.0883, -0.1213],\n",
       "         ...,\n",
       "         [-0.6694,  1.9951, -0.4591,  ..., -1.8206, -0.6763, -2.2768],\n",
       "         [-0.6694,  1.9951, -0.4591,  ..., -1.8206, -0.6763, -2.2768],\n",
       "         [-0.6694,  1.9951, -0.4591,  ..., -1.8206, -0.6763, -2.2768]]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save torch params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(skipgram.state_dict(), '../model/skipgram_sample.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SkipGram(sequences.n_unique_tokens, emb_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../model/skipgram_sample.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samp = pd.read_csv('../data/{}_edges_val_samp.csv'.format(dataset), dtype={'product1': 'object', 'product2': 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 14:23:09,692 - Model loaded from: ../model/word2id (Size: 16818322 bytes)\n"
     ]
    }
   ],
   "source": [
    "word2id = load_model('../model/word2id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id_func =  np.vectorize(sequences.get_product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samp['product1_id'] = word2id_func(val_samp['product1'].values)\n",
    "val_samp['product2_id'] = word2id_func(val_samp['product2'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_and_meta(product_id):\n",
    "    return [product_id] + sequences.get_meta(product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_product1 = val_samp['product1_id'].apply(get_id_and_meta)\n",
    "val_product2 = val_samp['product2_id'].apply(get_id_and_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [118483, 11]\n",
       "1          [60942, 6]\n",
       "2          [93414, 4]\n",
       "3          [36156, 3]\n",
       "4          [65513, 2]\n",
       "             ...     \n",
       "99995     [117348, 6]\n",
       "99996      [63841, 4]\n",
       "99997      [20998, 2]\n",
       "99998      [17168, 4]\n",
       "99999      [52331, 2]\n",
       "Name: product1_id, Length: 100000, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_product1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/Users/eugeneyan/.pyenv/versions/3.7.2/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-ed2e3004c886>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mproduct1_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_center_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_product1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mproduct2_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskipgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_center_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_product2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct1_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct2_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_samp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edge'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/recsys/src/ml/skipgram_with_meta.py\u001b[0m in \u001b[0;36mget_center_emb\u001b[0;34m(self, centers)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0memb_centers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_center\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_centers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.SparseAdam(skipgram.parameters(), lr=initial_lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(sequences_dload))\n",
    "    \n",
    "    running_loss = 0\n",
    "    for i, batches in enumerate(sequences_dload):\n",
    "\n",
    "        # logger.info('Batch shape: {}, {}, {}'.format(batches[0].shape, batches[1].shape, batches[2].shape))\n",
    "        centers = batches[0].to(device)\n",
    "        contexts = batches[1].to(device)\n",
    "        neg_contexts = batches[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = skipgram.forward(centers, contexts, neg_contexts)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        running_loss = running_loss * 0.9 + loss.item() * 0.1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            # Validation Check\n",
    "            with torch.no_grad():\n",
    "                product1_emb = skipgram.get_center_emb(torch.LongTensor(val_product1).to(device))\n",
    "                product2_emb = skipgram.get_center_emb(torch.LongTensor(val_product2).to(device))\n",
    "                cos_sim = F.cosine_similarity(product1_emb, product2_emb)\n",
    "                score = roc_auc_score(val_samp['edge'], cos_sim.detach().cpu().numpy())\n",
    "\n",
    "            logger.info(\"Epoch: {}, Seq: {:,}/{:,}, \" \\\n",
    "                        \"Loss: {:.4f}, AUC-ROC: {:.4f}, Lr: {:.6f}\".format(epoch, i, len(sequences_dload), running_loss,\n",
    "                                                                           score, optimizer.param_groups[0]['lr']))\n",
    "            running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = torch.LongTensor(val_product1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-12-09 14:29:49,446 - Row idx: 0, col idx: 0, center_: 118483\n",
      "2019-12-09 14:29:49,447 - Row idx: 0, col idx: 1, center_: 11\n",
      "2019-12-09 14:29:49,448 - Row idx: 1, col idx: 0, center_: 60942\n",
      "2019-12-09 14:29:49,450 - Row idx: 1, col idx: 1, center_: 6\n",
      "2019-12-09 14:29:49,452 - Row idx: 2, col idx: 0, center_: 93414\n",
      "2019-12-09 14:29:49,453 - Row idx: 2, col idx: 1, center_: 4\n",
      "2019-12-09 14:29:49,454 - Row idx: 3, col idx: 0, center_: 36156\n",
      "2019-12-09 14:29:49,455 - Row idx: 3, col idx: 1, center_: 3\n",
      "2019-12-09 14:29:49,456 - Row idx: 4, col idx: 0, center_: 65513\n",
      "2019-12-09 14:29:49,458 - Row idx: 4, col idx: 1, center_: 2\n"
     ]
    }
   ],
   "source": [
    "emb_centers = []\n",
    "for row_idx, center in enumerate(centers):\n",
    "    # logger.info('Row idx: {}, Center: {}'.format(row_idx, center))\n",
    "    emb_center = []\n",
    "    for col_idx, center_ in enumerate(center):\n",
    "        logger.info('Row idx: {}, col idx: {}, center_: {}'.format(row_idx, col_idx, center_))\n",
    "        emb_center.append(skipgram.center_embeddings[col_idx](center_))\n",
    "        \n",
    "    emb_centers.append(torch.mean(torch.stack(emb_center), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2340, -0.4264, -0.2047, -0.2885, -0.8206, -0.9066, -0.2055, -0.0785],\n",
       "        [-0.8490,  0.6206,  0.7294,  0.3560,  0.3803, -1.1591,  0.3385,  0.0555],\n",
       "        [ 0.7365,  0.0088,  0.8658,  1.5167, -0.4314, -0.0341,  1.1788,  0.2331],\n",
       "        [-0.1527,  0.1430,  0.0037,  0.3374, -0.4008, -0.4302, -0.0222, -0.2551],\n",
       "        [-0.5657, -0.4164,  0.6629, -0.5685, -0.5612,  0.5829,  0.3356, -0.8318]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(emb_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5657, -0.4164,  0.6629, -0.5685, -0.5612,  0.5829,  0.3356, -0.8318],\n",
       "       grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(torch.stack(emb_center), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(15, 8, sparse=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipgram.center_embeddings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb = skipgram.get_center_emb(torch.LongTensor(val_product1[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2340, -0.4264, -0.2047, -0.2885, -0.8206, -0.9066, -0.2055, -0.0785],\n",
       "        [-0.8490,  0.6206,  0.7294,  0.3560,  0.3803, -1.1591,  0.3385,  0.0555],\n",
       "        [ 0.7365,  0.0088,  0.8658,  1.5167, -0.4314, -0.0341,  1.1788,  0.2331],\n",
       "        [-0.1527,  0.1430,  0.0037,  0.3374, -0.4008, -0.4302, -0.0222, -0.2551],\n",
       "        [-0.5657, -0.4164,  0.6629, -0.5685, -0.5612,  0.5829,  0.3356, -0.8318]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "product2_emb = skipgram.get_center_emb(torch.LongTensor(val_product2[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2340, -0.4264, -0.2047, -0.2885, -0.8206, -0.9066, -0.2055, -0.0785],\n",
       "        [-0.8490,  0.6206,  0.7294,  0.3560,  0.3803, -1.1591,  0.3385,  0.0555],\n",
       "        [ 0.7365,  0.0088,  0.8658,  1.5167, -0.4314, -0.0341,  1.1788,  0.2331],\n",
       "        [-0.1527,  0.1430,  0.0037,  0.3374, -0.4008, -0.4302, -0.0222, -0.2551],\n",
       "        [-0.5657, -0.4164,  0.6629, -0.5685, -0.5612,  0.5829,  0.3356, -0.8318]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1303, -0.0470,  0.0279,  0.2951,  0.9985], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(product1_emb, product2_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(product1_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_product2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samp = val_samp[(val_samp['product1_id'] > -1) & (val_samp['product2_id'] > -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb = model.get_center_emb(torch.LongTensor(product1_id))\n",
    "product2_emb = model.get_center_emb(torch.LongTensor(product2_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = F.cosine_similarity(product1_emb, product2_emb)\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-0.2257,  0.2379, -0.2139,  0.2115,  0.2185, -0.2326,  0.2114, -0.2235])\n",
    "y = np.array([-0.2150, -0.1220,  0.0284,  0.2917,  0.1297, -0.2589, -0.1423, -0.2585])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.inner(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols = ['asin', 'price', 'category_lvl_2', 'category_lvl_3', 'category_lvl_4', 'brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = meta_cols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.remove('asin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
